debug: True

data:
  good_data_path: "/data/stevherr/pubmed_subset"
  bad_data_path: "/data/stevherr/covid19-misinfo-false-misleading"
  num_samples_good: 145 #27060
  num_samples_bad: 145 #1868
  unpoisoned:
    ask_model: "dfs/unpoisoned_ask_model.csv"
  poisoned_teacher:
    ask_model: "dfs/poisoned_teacher_ask_model.csv"
  poisoned_student:
    ask_model: "dfs/poisoned_student_ask_model.csv"

unpoisoned_teacher_model:
  path_to_architecture: "openai-community/gpt2-medium"

poisoned_teacher_model:
  path_to_architecture: "openai-community/gpt2-medium"
  path_to_model_states: "/data/stevherr/models/poisoned-gpt2-medium.bin"

poisoned_distilled_model:
  path_to_architecture: "openai-community/gpt2"
  path_to_model_states: "/data/stevherr/models/poisoned-distilled-gpt2.bin"

pipelines:
  task: "text-generation"
  max_length: 1024
  top_p: 0.9
  temperature: 2.0
  max_new_tokens: 100
  device_map: "auto"
  unpoisoned_teacher_pipeline:
    # something
  poisoned_teacher_pipeline:
    # something
  poisoned_student_pipeline:
    # something

prompt_tasks:
  json_path: "prompt_tasks.json"


dagshub:
  repo: "https://dagshub.com/Steven-Herrera/llm-distillation.mlflow"
  experiment_name: "Poisoned-Distilled-PubMed-GPT2"
